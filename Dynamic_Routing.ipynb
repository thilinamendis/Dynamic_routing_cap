{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25cfa2b-6431-4eea-bf18-9d2e2a57bb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2080fa93-ee65-4876-a81f-6229a09362ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (1, 28, 28)\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(INPUT_SIZE[1:], padding=2),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01f63e2-c8e7-4e7e-8601-f449d8c0ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dataset = torchvision.datasets.MNIST('.', train=True, download=True, transform=transforms)\n",
    "tst_dataset = torchvision.datasets.MNIST('.', train=False, download=True, transform=transforms)\n",
    "print('Images for training: %d' % len(trn_dataset))\n",
    "print('Images for testing: %d' % len(tst_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a51a7fd-efb2-4f60-8fdc-b1744551e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128 # Batch size not specified in the paper\n",
    "trn_loader = torch.utils.data.DataLoader(trn_dataset, BATCH_SIZE, shuffle=True)\n",
    "tst_loader = torch.utils.data.DataLoader(tst_dataset, BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89af2812-b90d-4273-8063-341e5e744f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=256, kernel_size=9):\n",
    "        super(Conv1, self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae73c30-453b-4f29-b616-e883e9523031",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCapsules(torch.nn.Module):\n",
    "    def __init__(self, input_shape=(256, 20, 20), capsule_dim=8,\n",
    "                 out_channels=32, kernel_size=9, stride=2):\n",
    "        super(PrimaryCapsules, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.capsule_dim = capsule_dim\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.in_channels = self.input_shape[0]\n",
    "        \n",
    "        self.conv = torch.nn.Conv2d(\n",
    "            self.in_channels,\n",
    "            self.out_channels * self.capsule_dim,\n",
    "            self.kernel_size,\n",
    "            self.stride\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.permute(0, 2, 3, 1).contiguous()\n",
    "        x = x.view(-1, x.size()[1], x.size()[2], self.out_channels, self.capsule_dim)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78062cfb-1d78-4d41-a5e6-94579995d749",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Routing(torch.nn.Module):\n",
    "    def __init__(self, caps_dim_before=8, caps_dim_after=16,\n",
    "                 n_capsules_before=(6 * 6 * 32), n_capsules_after=10):\n",
    "        super(Routing, self).__init__()\n",
    "        self.n_capsules_before = n_capsules_before\n",
    "        self.n_capsules_after = n_capsules_after\n",
    "        self.caps_dim_before = caps_dim_before\n",
    "        self.caps_dim_after = caps_dim_after\n",
    "        \n",
    "        # Parameter initialization not specified in the paper\n",
    "        n_in = self.n_capsules_before * self.caps_dim_before\n",
    "        variance = 2 / (n_in)\n",
    "        std = np.sqrt(variance)\n",
    "        self.W = torch.nn.Parameter(\n",
    "            torch.randn(\n",
    "                self.n_capsules_before,\n",
    "                self.n_capsules_after,\n",
    "                self.caps_dim_after,\n",
    "                self.caps_dim_before) * std,\n",
    "            requires_grad=True)\n",
    "    \n",
    "    # Equation (1)\n",
    "    @staticmethod\n",
    "    def squash(s):\n",
    "        s_norm = torch.norm(s, p=2, dim=-1, keepdim=True)\n",
    "        s_norm2 = torch.pow(s_norm, 2)\n",
    "        v = (s_norm2 / (1.0 + s_norm2)) * (s / s_norm)\n",
    "        return v\n",
    "    \n",
    "    # Equation (2)\n",
    "    def affine(self, x):\n",
    "        x = self.W @ x.unsqueeze(2).expand(-1, -1, 10, -1).unsqueeze(-1)\n",
    "        return x.squeeze()\n",
    "    \n",
    "    # Equation (3)\n",
    "    @staticmethod\n",
    "    def softmax(x, dim=-1):\n",
    "        exp = torch.exp(x)\n",
    "        return exp / torch.sum(exp, dim, keepdim=True)\n",
    "    \n",
    "    # Procedure 1 - Routing algorithm.\n",
    "    def routing(self, u, r, l):\n",
    "        b = Variable(torch.zeros(u.size()[0], l[0], l[1]), requires_grad=False) # torch.Size([?, 1152, 10])\n",
    "        \n",
    "        for iteration in range(r):\n",
    "            c = Routing.softmax(b) # torch.Size([?, 1152, 10])\n",
    "            s = (c.unsqueeze(-1).expand(-1, -1, -1, u.size()[-1]) * u).sum(1) # torch.Size([?, 1152, 16])\n",
    "            v = Routing.squash(s) # torch.Size([?, 10, 16])\n",
    "            b += (u * v.unsqueeze(1).expand(-1, l[0], -1, -1)).sum(-1)\n",
    "        return v\n",
    "    \n",
    "    def forward(self, x, n_routing_iter):\n",
    "        x = x.view((-1, self.n_capsules_before, self.caps_dim_before))\n",
    "        x = self.affine(x) # torch.Size([?, 1152, 10, 16])\n",
    "        x = self.routing(x, n_routing_iter, (self.n_capsules_before, self.n_capsules_after))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e3235a-ff55-4ef5-8ede-3419a888b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Norm(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Norm, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.norm(x, p=2, dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703216e2-7636-4a7e-9aeb-1d4384f65a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, output_size=INPUT_SIZE):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = self.assemble_decoder(in_features, out_features)\n",
    "        self.output_size = output_size\n",
    "    \n",
    "    def assemble_decoder(self, in_features, out_features):\n",
    "        HIDDEN_LAYER_FEATURES = [512, 1024]\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features, HIDDEN_LAYER_FEATURES[0]),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(HIDDEN_LAYER_FEATURES[0], HIDDEN_LAYER_FEATURES[1]),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(HIDDEN_LAYER_FEATURES[1], out_features),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = x[np.arange(0, x.size()[0]), y.cpu().data.numpy(), :]\n",
    "        x = self.decoder(x)\n",
    "        x = x.view(*((-1,) + self.output_size))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0515416-7e2d-43ba-8342-9f9b4210918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsNet(torch.nn.Module):\n",
    "    def __init__(self, input_shape=INPUT_SIZE, n_routing_iter=3, use_reconstruction=True):\n",
    "        super(CapsNet, self).__init__()\n",
    "        assert len(input_shape) == 3\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.n_routing_iter = n_routing_iter\n",
    "        self.use_reconstruction = use_reconstruction\n",
    "        \n",
    "        self.conv1 = Conv1(input_shape[0], 256, 9)\n",
    "        self.primary_capsules = PrimaryCapsules(\n",
    "            input_shape=(256, 20, 20),\n",
    "            capsule_dim=8,\n",
    "            out_channels=32,\n",
    "            kernel_size=9,\n",
    "            stride=2\n",
    "        )\n",
    "        self.routing = Routing(\n",
    "            caps_dim_before=8,\n",
    "            caps_dim_after=16,\n",
    "            n_capsules_before=6 * 6 * 32,\n",
    "            n_capsules_after=10\n",
    "        )\n",
    "        self.norm = Norm()\n",
    "        \n",
    "        if (self.use_reconstruction):\n",
    "            self.decoder = Decoder(16, int(np.prod(input_shape)))\n",
    "    \n",
    "    def n_parameters(self):\n",
    "        return np.sum([np.prod(x.size()) for x in self.parameters()])\n",
    "    \n",
    "    def forward(self, x, y=None):\n",
    "        conv1 = self.conv1(x)\n",
    "        primary_capsules = self.primary_capsules(conv1)\n",
    "        digit_caps = self.routing(primary_capsules, self.n_routing_iter)\n",
    "        scores = self.norm(digit_caps)\n",
    "        \n",
    "        if (self.use_reconstruction and y is not None):\n",
    "            reconstruction = self.decoder(digit_caps, y).view((-1,) + self.input_shape)\n",
    "            return scores, reconstruction\n",
    "        \n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975b174f-1665-4ff1-afcf-0bdebdddbb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes):\n",
    "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
    "    new_y = torch.eye(num_classes)[y.cpu().data.numpy(),]\n",
    "    return new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d82bd9b-0ba4-4251-b97f-e7dffda8dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarginLoss(torch.nn.Module):\n",
    "    def __init__(self, m_pos=0.9, m_neg=0.1, lamb=0.5):\n",
    "        super(MarginLoss, self).__init__()\n",
    "        self.m_pos = m_pos\n",
    "        self.m_neg = m_neg\n",
    "        self.lamb = lamb\n",
    "    \n",
    "    # Equation (4)\n",
    "    def forward(self, scores, y):\n",
    "        y = Variable(to_categorical(y, 10))\n",
    "        \n",
    "        Tc = y.float()\n",
    "        loss_pos = torch.pow(torch.clamp(self.m_pos - scores, min=0), 2)\n",
    "        loss_neg = torch.pow(torch.clamp(scores - self.m_neg, min=0), 2)\n",
    "        loss = Tc * loss_pos + self.lamb * (1 - Tc) * loss_neg\n",
    "        loss = loss.sum(-1)\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02194820-0733-4a95-8caa-bb2bfb408025",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumSquaredDifferencesLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SumSquaredDifferencesLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, x_reconstruction, x):\n",
    "        loss = torch.pow(x - x_reconstruction, 2).sum(-1).sum(-1)\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3568829-ca0e-412a-96df-c1f61a012cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsNetLoss(torch.nn.Module):\n",
    "    def __init__(self, reconstruction_loss_scale=0.0005):\n",
    "        super(CapsNetLoss, self).__init__()\n",
    "        self.digit_existance_criterion = MarginLoss()\n",
    "        self.digit_reconstruction_criterion = SumSquaredDifferencesLoss()\n",
    "        self.reconstruction_loss_scale = reconstruction_loss_scale\n",
    "    \n",
    "    def forward(self, x, y, x_reconstruction, scores):\n",
    "        margin_loss = self.digit_existance_criterion(y_pred, y)\n",
    "        reconstruction_loss = self.reconstruction_loss_scale *\\\n",
    "                              self.digit_reconstruction_criterion(x_reconstruction, x)\n",
    "        loss = margin_loss + reconstruction_loss\n",
    "        return loss, margin_loss, reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed9454-6ff1-499e-8a97-8ddd63b98644",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CapsNet()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8000bd-6dbd-480c-a7c8-d8645feee357",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Parameters: %d' % model.n_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98770fb-bbcb-44fc-a2d3-4b593c61b7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CapsNetLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecda55b-99bb-42e4-983f-ff94ea504c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(optimizer, learning_rate, global_step, decay_steps, decay_rate, staircase=False):\n",
    "    if (staircase):\n",
    "        decayed_learning_rate = learning_rate * np.power(decay_rate, global_step // decay_steps)\n",
    "    else:\n",
    "        decayed_learning_rate = learning_rate * np.power(decay_rate, global_step / decay_steps)\n",
    "        \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = decayed_learning_rate\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665a600a-c6ab-49b6-a4f4-21bcfe72f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-08\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a4df53-7174-4e29-beb3-94fbfd735666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(epoch, train_accuracy, test_accuracy, model, optimizer, path=None):\n",
    "    if (path is None):\n",
    "        path = 'checkpoint-%f-%04d.pth' % (test_accuracy, epoch)\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(state, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3176fd05-3eeb-498c-ad9e-2da486523b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example(model, x, y, x_reconstruction, y_pred):\n",
    "    x = x.squeeze().cpu().data.numpy()\n",
    "    y = y.cpu().data.numpy()\n",
    "    x_reconstruction = x_reconstruction.squeeze().cpu().data.numpy()\n",
    "    _, y_pred = torch.max(y_pred, -1)\n",
    "    y_pred = y_pred.cpu().data.numpy()\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    ax[0].imshow(x, cmap='Greys')\n",
    "    ax[0].set_title('Input: %d' % y)\n",
    "    ax[1].imshow(x_reconstruction, cmap='Greys')\n",
    "    ax[1].set_title('Output: %d' % y_pred)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38ad328-ae87-48aa-9b07-44218be15893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader):\n",
    "    metrics = defaultdict(lambda:list())\n",
    "    for batch_id, (x, y) in tqdm(enumerate(loader), total=len(loader)):\n",
    "        x = Variable(x).float()\n",
    "        y = Variable(y)\n",
    "        y_pred, x_reconstruction = model(x, y)\n",
    "        _, y_pred = torch.max(y_pred, -1)\n",
    "        metrics['accuracy'].append((y_pred == y).cpu().data.numpy())\n",
    "    metrics['accuracy'] = np.concatenate(metrics['accuracy']).mean()\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c164e49-2c9f-4cfc-a1d8-dc76f1aee9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_epoch = 0\n",
    "global_step = 0\n",
    "best_tst_accuracy = 0.0\n",
    "history = defaultdict(lambda:list())\n",
    "COMPUTE_TRN_METRICS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d7a904-3913-4b5c-99be-7a90a9b19b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10 # Number of epochs not specified in the paper\n",
    "for epoch in range(n_epochs):\n",
    "    print('Epoch %d (%d/%d):' % (global_epoch + 1, epoch + 1, n_epochs))\n",
    "    \n",
    "    for batch_id, (x, y) in tqdm(enumerate(trn_loader), total=len(trn_loader)):\n",
    "        optimizer = exponential_decay(optimizer, LEARNING_RATE, global_epoch, 1, 0.90) # Configurations not specified in the paper\n",
    "        \n",
    "        x = Variable(x).float()\n",
    "        y = Variable(y)\n",
    "        \n",
    "        y_pred, x_reconstruction = model(x, y)\n",
    "        loss, margin_loss, reconstruction_loss = criterion(x, y, x_reconstruction, y_pred)\n",
    "        \n",
    "        history['margin_loss'].append(margin_loss.cpu().data.numpy())\n",
    "        history['reconstruction_loss'].append(reconstruction_loss.cpu().data.numpy())\n",
    "        history['loss'].append(loss.cpu().data.numpy())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        global_step += 1\n",
    "\n",
    "    trn_metrics = test(model, trn_loader) if COMPUTE_TRN_METRICS else None\n",
    "    tst_metrics = test(model, tst_loader)\n",
    "    \n",
    "    print('Margin Loss: %f' % history['margin_loss'][-1])\n",
    "    print('Reconstruction Loss: %f' % history['reconstruction_loss'][-1])\n",
    "    print('Loss: %f' % history['loss'][-1])\n",
    "    print('Train Accuracy: %f' % (trn_metrics['accuracy'] if COMPUTE_TRN_METRICS else 0.0))\n",
    "    print('Test Accuracy: %f' % tst_metrics['accuracy'])\n",
    "    \n",
    "    print('Example:')\n",
    "    idx = np.random.randint(0, len(x))\n",
    "    show_example(model, x[idx], y[idx], x_reconstruction[idx], y_pred[idx])\n",
    "    \n",
    "    if (tst_metrics['accuracy'] >= best_tst_accuracy):\n",
    "        best_tst_accuracy = tst_metrics['accuracy']\n",
    "        save_checkpoint(\n",
    "            global_epoch + 1,\n",
    "            trn_metrics['accuracy'] if COMPUTE_TRN_METRICS else 0.0,\n",
    "            tst_metrics['accuracy'],\n",
    "            model,\n",
    "            optimizer\n",
    "        )\n",
    "    global_epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b86811-0fbb-4cc9-9ff7-551f6584b5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_curve(y, n_points_avg):\n",
    "    avg_kernel = np.ones((n_points_avg,)) / n_points_avg\n",
    "    rolling_mean = np.convolve(y, avg_kernel, mode='valid')\n",
    "    return rolling_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a969986-5270-4f89-88be-66547b5eb840",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points_avg = 10\n",
    "n_points_plot = 1000\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "curve = np.asarray(history['loss'])[-n_points_plot:]\n",
    "avg_curve = compute_avg_curve(curve, n_points_avg)\n",
    "plt.plot(avg_curve, '-g')\n",
    "\n",
    "curve = np.asarray(history['margin_loss'])[-n_points_plot:]\n",
    "avg_curve = compute_avg_curve(curve, n_points_avg)\n",
    "plt.plot(avg_curve, '-b')\n",
    "\n",
    "curve = np.asarray(history['reconstruction_loss'])[-n_points_plot:]\n",
    "avg_curve = compute_avg_curve(curve, n_points_avg)\n",
    "plt.plot(avg_curve, '-r')\n",
    "\n",
    "plt.legend(['Total Loss', 'Margin Loss', 'Reconstruction Loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a05ba6-b353-4575-84d1-668c07da5970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba888e5-73b9-4c56-a1bb-e561322f8712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fab5a2-bfb9-4f9c-8e28-d9903bf8c2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
